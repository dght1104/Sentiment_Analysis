{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, GRU, Input, GlobalMaxPooling1D, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pyvi import ViTokenizer, ViUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userid', 'mtime', 'rating_star', 'comment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Đọc file CSV\n",
    "file_path = \"sentiments_v2.csv\"\n",
    "data = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "# In ra tên các cột để kiểm tra\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các cột trong DataFrame: Index(['userid', 'mtime', 'rating_star', 'comment'], dtype='object')\n",
      "                                             comment  sentiment\n",
      "0  Đồ giống hình, nhìn khá xinh, giá rẻ, ship siê...   0.295833\n",
      "1  Giao hàng nhanh. Mình đặt hộ nên ko biết chất ...   0.391667\n",
      "2  Sản phẩm giống trên hình. Son khá lì. Thời gia...  -0.025000\n",
      "3  Son xinh xĩu lun á shopp ơii.vỏ son nhìn cute ...   0.850000\n",
      "4  Cách xoá MỤN ĐẦU ĐEN mũi bằng DẦU TẨY TRANG. K...  -0.125000\n"
     ]
    }
   ],
   "source": [
    "# Đọc file CSV\n",
    "file_path = \"sentiments_v2.csv\"\n",
    "data = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "# In ra tên các cột để kiểm tra\n",
    "print(\"Các cột trong DataFrame:\", data.columns)\n",
    "\n",
    "# Chỉ kiểm tra nếu cột 'comment' tồn tại\n",
    "if 'comment' in data.columns:\n",
    "    # Khởi tạo công cụ dịch\n",
    "    translator = Translator()\n",
    "\n",
    "    # Hàm dịch và phân tích cảm xúc\n",
    "    def analyze_sentiment(text):\n",
    "        # Dịch văn bản sang tiếng Anh\n",
    "        translated_text = translator.translate(text, src='vi', dest='en').text\n",
    "        # Phân tích cảm xúc bằng TextBlob\n",
    "        blob = TextBlob(translated_text)\n",
    "        return blob.sentiment.polarity  # Trả về điểm cảm xúc từ -1 (tiêu cực) đến 1 (tích cực)\n",
    "\n",
    "    # Áp dụng hàm cho 5 bình luận đầu tiên\n",
    "    data['sentiment'] = data['comment'].head(5).apply(analyze_sentiment)\n",
    "\n",
    "    # Hiển thị 5 bình luận đầu tiên với điểm cảm xúc\n",
    "    print(data[['comment', 'sentiment']].head(5))\n",
    "else:\n",
    "    print(\"Cột 'comment' không tồn tại trong DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các cột trong DataFrame: Index(['userid', 'mtime', 'rating_star', 'comment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Đọc file CSV\n",
    "file_path = \"sentiments_v2_1_1000.csv\"\n",
    "data = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "# In ra tên các cột để kiểm tra\n",
    "print(\"Các cột trong DataFrame:\", data.columns)\n",
    "\n",
    "# Chỉ kiểm tra nếu cột 'comment' tồn tại\n",
    "if 'comment' in data.columns:\n",
    "    # Khởi tạo công cụ dịch\n",
    "    translator = Translator()\n",
    "\n",
    "    # Hàm dịch và phân tích cảm xúc\n",
    "    def analyze_sentiment(text):\n",
    "        # Kiểm tra nếu văn bản không phải là None hoặc chuỗi rỗng\n",
    "        if isinstance(text, str) and text.strip():\n",
    "            try:\n",
    "                # Dịch văn bản sang tiếng Anh\n",
    "                translated_text = translator.translate(text, src='vi', dest='en').text\n",
    "                # Phân tích cảm xúc bằng TextBlob\n",
    "                blob = TextBlob(translated_text)\n",
    "                return blob.sentiment.polarity  # Trả về điểm cảm xúc từ -1 (tiêu cực) đến 1 (tích cực)\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi dịch văn bản: {e}\")\n",
    "                return None  # Trả về None nếu có lỗi\n",
    "        else:\n",
    "            return None  # Trả về None cho các văn bản không hợp lệ\n",
    "\n",
    "    # Tạo cột mới 'sentiment' và áp dụng hàm cho toàn bộ cột 'comment'\n",
    "    data['sentiment'] = data['comment'].apply(lambda x: analyze_sentiment(x) if x is not None else None)\n",
    "\n",
    "    # Hiển thị 5 bình luận đầu tiên với điểm cảm xúc\n",
    "    print(data[['comment', 'sentiment']].head(5))\n",
    "\n",
    "    # Lưu DataFrame trở lại file CSV với cột mới\n",
    "    data.to_csv(\"sentiments.csv\", index=False)\n",
    "else:\n",
    "    print(\"Cột 'comment' không tồn tại trong DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.341, 'neu': 0.659, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"Hôm nay tôi bị công an bắt\"\n",
    "translated_text = translator.translate(text, src='vi', dest='en').text\n",
    "sentiment = analyzer.polarity_scores(translated_text)\n",
    "print(sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cpu\n",
      "CUDA available: False\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Sử dụng mô hình PhoBERT\u001b[39;00m\n\u001b[0;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvinai/phobert-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvinai/phobert-base\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Tokenize và xử lý câu\u001b[39;00m\n\u001b[0;32m     13\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTôi rất hài lòng với sản phẩm này\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1651\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1651\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1630\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Kiểm tra PyTorch\n",
    "print(\"PyTorch version:\", torch.__version__)  # Kiểm tra phiên bản PyTorch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # Kiểm tra xem có GPU không (dành cho phiên bản GPU)\n",
    "\n",
    "# Sử dụng mô hình PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=2)\n",
    "\n",
    "# Tokenize và xử lý câu\n",
    "sentence = \"Tôi rất hài lòng với sản phẩm này\"\n",
    "tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "print(tokens)  # In ra kết quả token hóa\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
